{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This notebook was created to do holdout testing on the hybrid combiner\n",
    "# It relies on a data extract in certain formats to operate, although there is a mock data generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Mock Data\n",
    "\n",
    "NUM_OF_CUSTOMERS = 150000\n",
    "NUM_OF_PRODUCTS = 3990\n",
    "NUM_OF_CATEGORIES = 8000 #level 1 + 1 general\n",
    "NUM_OF_CATEGORY_MAXMAPPINGS = 7\n",
    "NUM_OF_DEMOREGION = (9+1+1)  # 9 us regions + 1 international + 1 unknown, \n",
    "NUM_OF_DEMOGENDER = (2+1) # 2 genders + 1 unknown\n",
    "    \n",
    "# create symmetric matrix\n",
    "def random_symmetric_matrix(n,low,high):\n",
    "    _R = np.random.randint(low,high,size=n*(n-1)/2)\n",
    "    P = np.zeros((n,n))\n",
    "    P[np.triu_indices(n, 1)] = _R\n",
    "    P[np.tril_indices(n, -1)] = P.T[np.tril_indices(n, -1)]\n",
    "    return P\n",
    "\n",
    "# create product to category array\n",
    "def create_mock_prod_cat(num_prod,num_cat,max_mappings):\n",
    "    list_cat_mappings = []\n",
    "    for i in range(max_mappings):\n",
    "        list_cat_mappings.append(np.c_[np.random.randint(0,num_cat,num_prod),\\\n",
    "                                       np.random.randint(0,num_cat,num_prod),\\\n",
    "                                       np.random.randint(0,num_cat,num_prod),\\\n",
    "                                       np.random.randint(0,num_cat,num_prod),\\\n",
    "                                       np.random.randint(0,num_cat,num_prod)])\n",
    "    return np.array(list_cat_mappings)\n",
    "\n",
    "# create customer to demographics array\n",
    "def create_mock_cust_demo(num_cust,num_demoregion, num_demogender):\n",
    "    return np.c_[np.random.randint(0,num_demoregion,num_cust),\\\n",
    "                np.random.randint(0,num_demogender,num_cust)]\n",
    "\n",
    "# create customer x orders\n",
    "def create_mock_cust_orders(num_cust,num_prod,order_percentage):\n",
    "    R = np.random.choice([0, 1], size=num_cust*num_prod, p=[1-order_percentage, order_percentage])\n",
    "    return np.reshape(R,(-1,num_prod))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create co-occurrence matrix\n",
    "\n",
    "def create_cocmatrix(subset_matrix_cust_order):\n",
    "    rows, cols = subset_matrix_cust_order.shape\n",
    "    m = np.zeros((cols,cols))\n",
    "    for i in range(cols):\n",
    "        t = np.sum(subset_matrix_cust_order[subset_matrix_cust_order[:,i] > 0],axis=0)\n",
    "        t[i] = 0\n",
    "        m[i,:] = t\n",
    "        if i % (cols/5) == 0:\n",
    "            print \"created rows in cooccurrence matrix at row\",i\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_seed(rand):\n",
    "    np.random.seed(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created customer to demographic lookup\n",
      "created customer to order lookup\n",
      "created content lookup\n"
     ]
    }
   ],
   "source": [
    "# initialize all data for collaborative\n",
    "\n",
    "# customer to demographic lookup\n",
    "#arr_cxd = create_mock_cust_demo(NUM_OF_CUSTOMERS,NUM_OF_DEMOREGION,NUM_OF_DEMOGENDER)\n",
    "#arr_cxd = np.load('demo_matrix.npy')\n",
    "arr_cxd = np.load('../../data/extracts/cluster1CustmeridsMapping.npy')\n",
    "\n",
    "print \"created customer to demographic lookup\"\n",
    "\n",
    "# customer to order lookup\n",
    "#matrix_co = create_mock_cust_orders(NUM_OF_CUSTOMERS,NUM_OF_PRODUCTS,0.01)\n",
    "matrix_co = np.load('../../data/extracts/cust_item_matrix.npy')\n",
    "\n",
    "print \"created customer to order lookup\"\n",
    "\n",
    "# content rating lookup\n",
    "arr_conrate = np.load('../../data/derived/rating_indexed.npy')\n",
    "\n",
    "print \"created content lookup\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "customer x demographic shape: (189559, 1)\n",
      "customer regions + unknown: 8\n",
      "\tregion 0.0 % of pop 2.59708059232\n",
      "\tregion 1.0 % of pop 23.4512737459\n",
      "\tregion 2.0 % of pop 3.5403225381\n",
      "\tregion 3.0 % of pop 17.3581839955\n",
      "\tregion 4.0 % of pop 19.4113706023\n",
      "\tregion 5.0 % of pop 9.34695793922\n",
      "\tregion 6.0 % of pop 1.4955765751\n",
      "\tregion 7.0 % of pop 22.7992340116\n",
      "\n",
      "customer x purchases shape: (189559, 3990)\n",
      "if already normalized the stats should be the same\n",
      "not normalized\n",
      "customer average purchases (multiples of item allowed): 1.44386180556\n",
      "customer variance purchases (multiples of item allowed): 1.28894093873\n",
      "customer min purchases (multiples of item allowed): 1.0\n",
      "customer max purchases (multiples of item allowed): 150.0\n",
      "normalized\n",
      "customer average purchases (multiples of item set to 1): 1.44386180556\n",
      "customer variance purchases (multiples of item set to 1): 1.28894093873\n",
      "customer min purchases (multiples of item set to 1): 1\n",
      "customer max purchases (multiples of item set to 1): 150\n",
      "customers that bought at least 1 item: 189559\n",
      "customers that bought at least 2 item: 51204\n",
      "customers that bought at least 3 item: 18685\n",
      "customers that bought at least 4 item: 6562\n",
      "customers that bought at least 5 item: 3069\n"
     ]
    }
   ],
   "source": [
    "# print statistics\n",
    "\n",
    "print \"\\ncustomer x demographic shape:\",arr_cxd.shape\n",
    "print \"customer regions + unknown:\",len(np.unique(arr_cxd[:,0]))\n",
    "for num, name in enumerate(np.unique(arr_cxd[:,0])):\n",
    "    print \"\\tregion\",name,\"% of pop\",len(np.where(arr_cxd[:,0] == name)[0])/float(arr_cxd.shape[0])*100\n",
    "#print \"customer genders + unknown:\",len(np.unique(arr_cxd[:,1]))\n",
    "#for num, name in enumerate(np.unique(arr_cxd[:,1])):\n",
    "#    print \"\\tgender\",name,\"% of pop\",len(np.where(arr_cxd[:,1] == name)[0])/float(arr_cxd.shape[0])*100\n",
    "    \n",
    "print \"\\ncustomer x purchases shape:\",matrix_co.shape\n",
    "print \"if already normalized the stats should be the same\"\n",
    "print \"not normalized\"\n",
    "stat_sum_not_normal = np.sum(matrix_co,axis=1)\n",
    "print \"customer average purchases (multiples of item allowed):\",np.mean(stat_sum_not_normal)\n",
    "print \"customer variance purchases (multiples of item allowed):\",np.var(stat_sum_not_normal)\n",
    "print \"customer min purchases (multiples of item allowed):\",np.min(stat_sum_not_normal)\n",
    "print \"customer max purchases (multiples of item allowed):\",np.max(stat_sum_not_normal)\n",
    "print \"normalized\"\n",
    "stat_sum_normal = np.count_nonzero(matrix_co,axis=1)\n",
    "print \"customer average purchases (multiples of item set to 1):\",np.mean(stat_sum_normal)\n",
    "print \"customer variance purchases (multiples of item set to 1):\",np.var(stat_sum_normal)\n",
    "print \"customer min purchases (multiples of item set to 1):\",np.min(stat_sum_normal)\n",
    "print \"customer max purchases (multiples of item set to 1):\",np.max(stat_sum_normal)\n",
    "print \"customers that bought at least 1 item:\",len(np.where(np.sum(matrix_co,axis=1) > 0)[0])\n",
    "print \"customers that bought at least 2 item:\",len(np.where(np.sum(matrix_co,axis=1) > 1)[0])\n",
    "print \"customers that bought at least 3 item:\",len(np.where(np.sum(matrix_co,axis=1) > 2)[0])\n",
    "print \"customers that bought at least 4 item:\",len(np.where(np.sum(matrix_co,axis=1) > 3)[0])\n",
    "print \"customers that bought at least 5 item:\",len(np.where(np.sum(matrix_co,axis=1) > 4)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate recommendations\n",
    "# purchase_vec = customer purchases (vector)\n",
    "# cocm = co occurrence matrix [items x items]\n",
    "# num_rec = number of recommendations\n",
    "def gen_recom_collab(purchase_list,cocm,num_rec):\n",
    "    rowsum = np.zeros(cocm.shape[0])\n",
    "    \n",
    "    for p in purchase_list:\n",
    "        rowsum += cocm[p,:]\n",
    "        \n",
    "    rowsum[purchase_list] = 0\n",
    "    indices = np.nonzero(rowsum)[0]\n",
    "    toprec = indices[np.argsort(rowsum[indices])][-1 * num_rec:][::-1]\n",
    "    return list(toprec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate recommendations\n",
    "# purchase_vec = customer purchases (vector)\n",
    "# list_rating = content rating\n",
    "# num_rec = number of recommendations\n",
    "def gen_recom_content(purchase_list,list_rating,num_rec):\n",
    "    NUM_RECOMMENDATIONS_C = 40\n",
    "    rowsum = np.copy(list_rating)\n",
    "        \n",
    "    rowsum[purchase_list] = 0\n",
    "    \n",
    "    indices = np.nonzero(rowsum)[0]\n",
    "    randrec = indices[np.argsort(rowsum[indices])][-1 * NUM_RECOMMENDATIONS_C:][::-1]\n",
    "    randindices = np.random.permutation(randrec)[:num_rec]\n",
    "    toprec = randindices[np.argsort(rowsum[randindices])][::-1]\n",
    "    return list(toprec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put matrixes in to get cross validation recall\n",
    "# generate recommendations\n",
    "# mco = matrix of customer to order [customer x items]\n",
    "# num_rec = number of recommendations\n",
    "# num_folds = k number of folds for cross validation\n",
    "# recall_remove = removed number from purchase history\n",
    "# important_c = important clusters that you want specialized matrix\n",
    "# coc = clusters of customers\n",
    "# c_rating = content rating array\n",
    "def hybrid_recall_holdout_tester(mco_train,mco_test,num_rec_collab,num_rec_content,recall_remove,important_c,coc_train,coc_test,c_rating):\n",
    "    # cross validation n-folds\n",
    "    start_time = time.time()\n",
    "    list_total_acc=[]\n",
    "        \n",
    "    list_sub_acc = []\n",
    "    # build co-occurrence matrixes\n",
    "    list_coo_matrix = {}\n",
    "    list_coo_matrix[0] = create_cocmatrix(mco_train)\n",
    "    for c in important_c:\n",
    "        list_sub = list(np.where(coc_train == c)[0])\n",
    "        list_coo_matrix[c] = create_cocmatrix(mco_train[list_sub])\n",
    "\n",
    "    # loop through test set\n",
    "    # for each customer in test pool\n",
    "    for i in range(mco_test.shape[0]):\n",
    "        p_vec = mco_test[i,:]\n",
    "        list_original_purchases = np.where(p_vec > 0)[0]\n",
    "        list_summed_coo_vec = []\n",
    "        list_content_vec = []\n",
    "        list_hybrid_vec = []\n",
    "\n",
    "        # randomly select indexes to leave out\n",
    "        list_removed_purchases = random.sample(list(list_original_purchases),recall_remove)\n",
    "        # remove\n",
    "        list_modified_purchases = list(set(list_original_purchases) - set(list_removed_purchases))\n",
    "\n",
    "        # content recomendation\n",
    "        list_content_vec = gen_recom_content(list_modified_purchases,c_rating,num_rec_collab+num_rec_content)\n",
    "\n",
    "        # only run tests on customers with > recall_remove purchases for prediction\n",
    "        # collab recommendation\n",
    "        if len(list_original_purchases) > recall_remove:\n",
    "            # get sum all purchases except ones left out\n",
    "            cust_cluster = coc_test[i][0]\n",
    "            if cust_cluster in important_c:\n",
    "                list_summed_coo_vec = gen_recom_collab(list_modified_purchases,list_coo_matrix[cust_cluster],num_rec_collab+num_rec_content)\n",
    "            else:\n",
    "                list_summed_coo_vec = gen_recom_collab(list_modified_purchases,list_coo_matrix[0],num_rec_collab+num_rec_content)\n",
    "            # check if return recommendations are in list\n",
    "\n",
    "        # Combiner\n",
    "        list_hybrid_vec = list_summed_coo_vec[:num_rec_collab]\n",
    "\n",
    "        for r in list_content_vec:\n",
    "            if len(list_hybrid_vec) >= num_rec_collab+num_rec_content:\n",
    "                break\n",
    "            if r not in list_hybrid_vec:\n",
    "                list_hybrid_vec.append(r)\n",
    "\n",
    "        #print 'purchased' + 'list_modified_purchases'\n",
    "        #print 'collab' + str(list_summed_coo_vec)\n",
    "        #print 'content' + str(list_content_vec)\n",
    "        #print 'hybrid' + str(list_hybrid_vec)\n",
    "        #print 'missing' + str(list_removed_purchases)\n",
    "\n",
    "        list_recommended_match = set(list_removed_purchases) & set(list_hybrid_vec)\n",
    "        acc = len(list_recommended_match)/float(len(list_removed_purchases))\n",
    "        list_sub_acc.append(acc)                \n",
    "        \n",
    "        \n",
    "    average = np.mean(list_sub_acc)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put matrixes in to get cross validation coverage\n",
    "# generate recommendations\n",
    "# mco = matrix of customer to order [customer x items]\n",
    "# num_rec = number of recommendations\n",
    "# num_folds = k number of folds for cross validation\n",
    "# recall_remove = removed number from purchase history\n",
    "# important_c = important clusters that you want specialized matrix\n",
    "# coc = clusters of customers\n",
    "# c_rating = content rating array\n",
    "def hybrid_catalog_holdout_tester(mco_train,mco_test,num_rec_collab,num_rec_content,recall_remove,important_c,coc_train,coc_test,c_rating):\n",
    "    # cross validation n-folds\n",
    "    start_time = time.time()\n",
    "    list_total_coverage=[]\n",
    "    \n",
    "    set_products = set()\n",
    "    # build co-occurrence matrix\n",
    "    list_coo_matrix = {}\n",
    "    list_coo_matrix[0] = create_cocmatrix(mco_train)\n",
    "    for c in important_c:\n",
    "        list_sub = list(np.where(coc_train == c)[0])\n",
    "        list_coo_matrix[c] = create_cocmatrix(mco_train[list_sub])\n",
    "\n",
    "    # loop through test set\n",
    "    # for each customer in test pool\n",
    "    for i in range(mco_test.shape[0]):\n",
    "        # purchase vector\n",
    "        p_vec = mco_test[i,:]\n",
    "        list_original_purchases = np.where(p_vec > 0)[0]\n",
    "        cust_cluster = coc_test[i][0]\n",
    "        if cust_cluster in important_c:\n",
    "            list_summed_coo_vec = gen_recom_collab(list_original_purchases,list_coo_matrix[cust_cluster],num_rec_collab+num_rec_content)\n",
    "        else:\n",
    "            list_summed_coo_vec = gen_recom_collab(list_original_purchases,list_coo_matrix[0],num_rec_collab+num_rec_content)\n",
    "        # content recomendation\n",
    "        list_content_vec = gen_recom_content(list_original_purchases,c_rating,num_rec_collab+num_rec_content)  \n",
    "\n",
    "        # Combiner\n",
    "        list_hybrid_vec = list_summed_coo_vec[:num_rec_collab]\n",
    "\n",
    "        for r in list_content_vec:\n",
    "            if len(list_hybrid_vec) >= num_rec_collab+num_rec_content:\n",
    "                break\n",
    "            if r not in list_hybrid_vec:\n",
    "                list_hybrid_vec.append(r)\n",
    "\n",
    "        set_products = set_products | set(list_hybrid_vec)\n",
    "\n",
    "    mean_sub_cov = float(len(set_products))/p_vec.shape[0]\n",
    "    list_total_coverage.append(mean_sub_cov)\n",
    "    \n",
    "    average = np.mean(list_total_coverage)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find all clusters, 0 is unknown and all\n",
    "unique_clusters = np.unique(arr_cxd[:,0])\n",
    "# define useful regions\n",
    "list_useful_clusters = [1,3,4,7]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#80/20, 80 for 10-fold cross validation, 20 for test set holdout\n",
    "create_seed(0)\n",
    "indices = np.random.permutation(matrix_co.shape[0])\n",
    "tsize = int(matrix_co.shape[0]*.8)\n",
    "\n",
    "# customer to order matrix\n",
    "matrix_co_training_idx, matrix_co_testing_idx  = indices[:tsize], indices[tsize:]\n",
    "matrix_co_training, matrix_co_testing = matrix_co[matrix_co_training_idx,:], matrix_co[matrix_co_testing_idx,:]\n",
    "\n",
    "# demo matrix\n",
    "arr_cxd_training_idx, arr_cxd_testing_idx = indices[:tsize], indices[tsize:]\n",
    "arr_cxd_training, arr_cxd_testing = arr_cxd[arr_cxd_training_idx,:], arr_cxd[arr_cxd_testing_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((151647, 3990), (151647, 1), (189559, 3990), (189559, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_co_training.shape, arr_cxd_training.shape, matrix_co.shape, arr_cxd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created rows in cooccurrence matrix at row 0\n",
      "created rows in cooccurrence matrix at row 798\n",
      "created rows in cooccurrence matrix at row 1596\n",
      "created rows in cooccurrence matrix at row 2394\n",
      "created rows in cooccurrence matrix at row 3192\n",
      "created rows in cooccurrence matrix at row 0\n",
      "created rows in cooccurrence matrix at row 798\n",
      "created rows in cooccurrence matrix at row 1596\n",
      "created rows in cooccurrence matrix at row 2394\n",
      "created rows in cooccurrence matrix at row 3192\n",
      "created rows in cooccurrence matrix at row 0\n",
      "created rows in cooccurrence matrix at row 798\n",
      "created rows in cooccurrence matrix at row 1596\n",
      "created rows in cooccurrence matrix at row 2394\n",
      "created rows in cooccurrence matrix at row 3192\n",
      "created rows in cooccurrence matrix at row 0\n",
      "created rows in cooccurrence matrix at row 798\n",
      "created rows in cooccurrence matrix at row 1596\n",
      "created rows in cooccurrence matrix at row 2394\n",
      "created rows in cooccurrence matrix at row 3192\n",
      "created rows in cooccurrence matrix at row 0\n",
      "created rows in cooccurrence matrix at row 798\n",
      "created rows in cooccurrence matrix at row 1596\n",
      "created rows in cooccurrence matrix at row 2394\n",
      "created rows in cooccurrence matrix at row 3192\n",
      "created rows in cooccurrence matrix at row 0\n",
      "created rows in cooccurrence matrix at row 798\n",
      "created rows in cooccurrence matrix at row 1596\n",
      "created rows in cooccurrence matrix at row 2394\n",
      "created rows in cooccurrence matrix at row 3192\n",
      "created rows in cooccurrence matrix at row 0\n",
      "created rows in cooccurrence matrix at row 798\n",
      "created rows in cooccurrence matrix at row 1596\n",
      "created rows in cooccurrence matrix at row 2394\n",
      "created rows in cooccurrence matrix at row 3192\n",
      "created rows in cooccurrence matrix at row 0\n",
      "created rows in cooccurrence matrix at row 798\n",
      "created rows in cooccurrence matrix at row 1596\n",
      "created rows in cooccurrence matrix at row 2394\n",
      "created rows in cooccurrence matrix at row 3192\n",
      "created rows in cooccurrence matrix at row 0\n",
      "created rows in cooccurrence matrix at row 798\n",
      "created rows in cooccurrence matrix at row 1596\n",
      "created rows in cooccurrence matrix at row 2394\n",
      "created rows in cooccurrence matrix at row 3192\n",
      "created rows in cooccurrence matrix at row 0\n",
      "created rows in cooccurrence matrix at row 798\n",
      "created rows in cooccurrence matrix at row 1596\n",
      "created rows in cooccurrence matrix at row 2394\n",
      "created rows in cooccurrence matrix at row 3192\n"
     ]
    }
   ],
   "source": [
    "# General test\n",
    "seed = 0\n",
    "create_seed(seed)\n",
    "\n",
    "# test set\n",
    "accuracy = hybrid_recall_holdout_tester(matrix_co_training,matrix_co_testing,\\\n",
    "                                        9,1,1,list_useful_clusters,\\\n",
    "                                        arr_cxd_training,arr_cxd_testing,arr_conrate)\n",
    "\n",
    "coverage = hybrid_catalog_holdout_tester(matrix_co_training,matrix_co_testing,\\\n",
    "                                        9,1,1,list_useful_clusters,\\\n",
    "                                        arr_cxd_training,arr_cxd_testing,arr_conrate)\n",
    "\n",
    "\n",
    "\n",
    "# small test\n",
    "#randidx_train = np.random.choice(matrix_co_training.shape[0], 100000, replace=False)\n",
    "#randidx_test = np.random.choice(matrix_co_testing.shape[0], 10000, replace=False)\n",
    "#accuracy = hybrid_recall_holdout_tester(matrix_co_training[randidx_train],matrix_co_testing[randidx_test],\\\n",
    "#                                        9,1,1,list_useful_clusters,\\\n",
    "#                                        arr_cxd_training[randidx_train],arr_cxd_testing[randidx_test],arr_conrate)\n",
    "\n",
    "#coverage = hybrid_catalog_holdout_tester(matrix_co_training[randidx_train],matrix_co_testing[randidx_test],\\\n",
    "#                                        9,1,1,list_useful_clusters,\\\n",
    "#                                        arr_cxd_training[randidx_train],arr_cxd_testing[randidx_test],arr_conrate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20949999999999999"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3275689223057644"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
